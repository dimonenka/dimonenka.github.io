<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>I am a research scientist in <strong>AI and Game Theory</strong>, including <strong>Multi-Agent Reinforcement Learning</strong> with a focus on <strong>incentive alignment</strong> and <strong>cooperation</strong>, as well as <strong>Automated Mechanism Design</strong>.</p> <p>Currently, I am a postdoc in the <a href="https://dds.technion.ac.il/" target="_blank" rel="noopener noreferrer">Data and Decision Sciences</a> faculty at Technion in Haifa, Israel. Prior to this, I pursued my doctoral studies at the Higher School of Economics in St. Petersburg, Russia, where I am expected to obtain a PhD in Artificial Intelligence and Machine Learning later in 2024. I was doing research in the <a href="https://game.hse.ru/en/" target="_blank" rel="noopener noreferrer">Game Theory and Decision Making</a> lab at the Higher School of Economics, as well as in the Reinforcement Learning unit of JetBrains Research.</p> <p>Contact me at <strong>divanov.ml@gmail.com</strong>.</p> <h2 style="color: inherit">Research Interests</h2> <p>My research lies at the intersection of AI and Game Theory, focusing on two main directions.</p> <p>One direction is to apply methods of Machine Learning to economic problems. As a notable example, automated design of economic mechanisms employs data-driven ML approaches to discover (approximately) optimal mechanisms with desirable properties, moving beyond traditional reliance on theorems and proofs. In this area, I have contributed to auction and contract design through deep learning.</p> <p>The other direction is to take an economic perspective on AI problems. This implies treating AI agents as entities with inherent incentives and preferences, which we cannot modify directly, but can influence externally through designed mechanisms â€“ rules governing their interactions with the world, each other, and us. This concept I study through the lens of Multi-Agent Reinforcement Learning.</p> <h2 style="color: inherit">Achievements</h2> <p>In 2020, I received a <a href="https://yandex.com/scholarships/" target="_blank" rel="noopener noreferrer">Yandex ML Prize</a> award based on my <a href="https://dl.acm.org/doi/abs/10.1145/3328526.3329642" target="_blank" rel="noopener noreferrer">EC publication</a>.</p> <p>I was also a part of a <a href="https://discourse.aicrowd.com/t/neurips-2020-flatland-winners/4010" target="_blank" rel="noopener noreferrer">team</a> that placed first in the <a href="https://www.aicrowd.com/challenges/flatland" target="_blank" rel="noopener noreferrer">Flatland</a> Multi-Agent RL competition at NeurIPS 2020. The task was to manage dense traffic in a simulated environment of complex railway networks, requiring planning and coordination. Our solution is described in a <a href="https://proceedings.mlr.press/v133/laurent21a/laurent21a.pdf" target="_blank" rel="noopener noreferrer">publication</a> at the NeurIPS competition track (Section 4.2).</p> </body></html>